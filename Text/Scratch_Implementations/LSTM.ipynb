{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcSziTSWFL3l",
        "outputId": "98e9405d-3ba0-4a28-a896-ad5b9650881b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/bittlingmayer/amazonreviews\n",
            "License(s): unknown\n",
            "Downloading amazonreviews.zip to /Users/yuvrajsingh/Desktop/Learning/Text/Scratch_Implementations\n",
            "100%|███████████████████████████████████████▉| 493M/493M [00:48<00:00, 10.0MB/s]\n",
            "100%|████████████████████████████████████████| 493M/493M [00:48<00:00, 10.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download bittlingmayer/amazonreviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LefCK0ThxmCO",
        "outputId": "d93e2ae2-ea9c-484f-ad4c-ff209c687b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  amazonreviews.zip\n",
            "  inflating: test.ft.txt.bz2         \n",
            "  inflating: train.ft.txt.bz2        \n"
          ]
        }
      ],
      "source": [
        "!unzip \"amazonreviews.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**SSL Certificates: A Security Shield for NLTK Data**\n",
        "\n",
        "SSL certificates play a crucial role in ensuring the secure transmission of data, including NLTK packages. By verifying the identity of the server and encrypting the data, SSL certificates protect against:\n",
        "\n",
        "* **Man-in-the-Middle Attacks:** Prevents unauthorized interception and modification of data.\n",
        "* **Data Tampering:** Ensures the integrity of downloaded NLTK packages.\n",
        "* **Malicious Code Injection:** Safeguards against the introduction of harmful software.\n",
        "\n",
        "**Ignoring SSL Certificate Errors: A Risky Proposition**\n",
        "\n",
        "Disregarding SSL certificate errors can expose your system to significant security vulnerabilities. It's strongly advised to address these errors by:\n",
        "\n",
        "* **Updating System Certificates:** Ensures you have the latest trusted certificates.\n",
        "* **Installing Certificates for Python Environment (Use with Caution):** A less secure alternative that should only be used if updating system certificates fails.\n",
        "\n",
        "By prioritizing SSL certificate verification, you can maintain the security and reliability of your NLTK environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkctn88SxYHg",
        "outputId": "6081beba-70cf-4945-823c-b7ff79f0b479"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "import seaborn as sns\n",
        "from rich import print\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 11.4 MB/s eta 0:00:00\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
            "[notice] To update, run: pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "spacy.cli.download(\"en_core_web_sm\")\n",
        "nlp = spacy.load(\"en_core_web_sm\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bPcyoOI9x9G8"
      },
      "outputs": [],
      "source": [
        "# Load the data (ensure the path matches your local setup)\n",
        "train_data = pd.read_csv('train.ft.txt.bz2', compression='bz2', delimiter='\\t', header=None).sample(15000, random_state=1000)\n",
        "test_data = pd.read_csv('test.ft.txt.bz2', compression='bz2', delimiter='\\t', header=None).sample(5000, random_state=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dDEuwiwKy5Ch"
      },
      "outputs": [],
      "source": [
        "# Resetting the index\n",
        "train_data.reset_index(drop=True,inplace=True)\n",
        "test_data.reset_index(drop=True,inplace=True)\n",
        "\n",
        "train_data.rename(columns={0: 'raw_text'}, inplace=True)\n",
        "test_data.rename(columns={0: 'raw_text'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iFh_Un7Fx4cC"
      },
      "outputs": [],
      "source": [
        "# Extracting the labels from the training and test data\n",
        "train_data['label'] = train_data['raw_text'].str.extract(r'(__label__\\d+)')[0]\n",
        "train_data['text'] = train_data['raw_text'].str.replace(r'__label__\\d+ ', '', regex=True)\n",
        "\n",
        "test_data['label'] = test_data['raw_text'].str.extract(r'(__label__\\d+)')[0]\n",
        "test_data['text'] = test_data['raw_text'].str.replace(r'__label__\\d+ ', '', regex=True)\n",
        "\n",
        "# Dropping the raw text feature and replacing the labels with positive and negative label\n",
        "train_data.drop(['raw_text'],axis=1,inplace=True)\n",
        "test_data.drop(['raw_text'],axis=1,inplace=True)\n",
        "\n",
        "train_data['label'] = train_data['label'].replace({'__label__2': 'positive', '__label__1': 'negative'})\n",
        "test_data['label'] = test_data['label'].replace({'__label__2': 'positive', '__label__1': 'negative'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TA0Qh_500QUd"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess the input text: lowercasing, punctuation removal,\n",
        "    stopword removal, and lemmatization.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Lowercase, remove punctuation, filter stopwords, and lemmatize using spaCy\n",
        "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop]\n",
        "    processed_text = ' '.join(tokens)\n",
        "\n",
        "    return embedding_model.encode(processed_text)\n",
        "\n",
        "# Define the target transform for one-hot encoding\n",
        "def target_transform(label):\n",
        "    num_classes = 2  # Number of classes: 'positive' and 'negative'\n",
        "    return one_hot(torch.tensor(label), num_classes=num_classes).float()\n",
        "\n",
        "# TextDataset Class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, text_column, label_column, transform=None, target_transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (pd.DataFrame): Input DataFrame containing text and labels.\n",
        "            text_column (str): Name of the column containing text data.\n",
        "            label_column (str): Name of the column containing labels.\n",
        "            transform (callable, optional): Transformation for text data (e.g., preprocessing).\n",
        "            target_transform (callable, optional): Transformation for target labels.\n",
        "        \"\"\"\n",
        "        self.data = df\n",
        "        self.texts = self.data[text_column].tolist()\n",
        "        self.labels = self.data[label_column].tolist()\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        # Convert textual labels (e.g., 'positive', 'negative') to integers\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.encoded_labels = self.label_encoder.fit_transform(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.encoded_labels[idx]\n",
        "\n",
        "        # Apply text preprocessing if specified\n",
        "        if self.transform:\n",
        "            text = self.transform(text)\n",
        "\n",
        "        # Apply target transformation (e.g., one-hot encoding) if specified\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return text, torch.tensor(label, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7JohKTs7Ie7",
        "outputId": "22a43fd8-5927-43de-dd40-3f3dc585627b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 5.45 ms, sys: 3.3 ms, total: 8.75 ms\n",
            "Wall time: 9.11 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Create a TextDataset instance\n",
        "train_dataset = TextDataset(\n",
        "    df=train_data,\n",
        "    text_column=\"text\",\n",
        "    label_column=\"label\",\n",
        "    transform=preprocess_text,\n",
        "    target_transform=target_transform\n",
        ")\n",
        "\n",
        "test_dataset = TextDataset(\n",
        "    df=test_data,\n",
        "    text_column=\"text\",\n",
        "    label_column=\"label\",\n",
        "    transform=preprocess_text,\n",
        "    target_transform=target_transform\n",
        ")\n",
        "\n",
        "# Wrap the dataset in a DataLoader for batching\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
